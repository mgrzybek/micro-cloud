version: 3
vars:
  hardwares:
    - hostname: node-0
      mac: "10:66:6a:07:8d:01"
      #- hostname: node-1
      #  mac: "10:66:6a:07:8d:02"
  skopeo_opts: --dest-tls-verify=false --override-arch=amd64 --override-os=linux
  ts_suffix:
    sh: tailscale dns status | awk '/suffix =/ {gsub(")","");print $NF}'
  cp_host: "192.168.3.8"
tasks:
  #############################################################################
  # Downloading and building artifacts
  # 
  populate-registry:
    desc: Add some OCI images into the registry
    vars:
      binaries:
        - butane
        - flatcar-install
    cmds:
      - for: {var: binaries}
        cmd: task --dir ../../common create-{{.ITEM}}-oci
      - for: {var: binaries}
        cmd: task --dir ../../common push-{{.ITEM}}-oci
      - |
        for image in $(yq '.oci[] | .source + "," + .destination' registry.yaml); do
          echo "Copying $image to $destination"
          new_name=$(echo $image | awk -F, '{print $2}' | awk '{gsub("^[a-z.]+/","");print}')
          source="docker://$(echo $image | awk -F, '{print $1'})"
          destination="docker://registry.{{.ts_suffix}}:443/$new_name"
          skopeo copy --dest-tls-verify=false --override-arch=amd64 --override-os=linux $source $destination
          echo
        done
  populate-extensions:
    desc: Add Kubernetes extension files to the assets service
    vars:
      files:
        - https://extensions.flatcar.org/extensions/kubernetes/kubernetes-v1.33.conf
        - https://extensions.flatcar.org/extensions/noop.conf
        - https://extensions.flatcar.org/extensions/kubernetes-v1.33.2-x86-64.raw
    cmds:
      - incus exec bootstrap -- mkdir -p /var/lib/matchbox/assets/flatcar/extensions
      - for: {var: files}
        cmd: incus exec --cwd /var/lib/matchbox/assets/flatcar/extensions bootstrap -- wget -nc {{.ITEM}}
  #############################################################################
  # Delete virtual instances and cluster
  # 
  delete-nodes:
    desc: Delete virtual instances and cluster
    prompt: Are you sure? That is going to delete the capi resources and the nodes.
    preconditions:
      - echo $BMAAS_NAMESPACE | grep -qe "[a-z]"
    cmds:
      - for: {var: hardwares}
        cmd: incus delete --force {{.ITEM.hostname}}
      - kubectl delete --wait -f dist/hardwares.yaml -f dist/capi-vm.yaml
      - rm -f dist/hardwares.yaml dist/capi-vm.yaml
  #############################################################################
  # Deploy virtual instances
  # 
  deploy-nodes:
    desc: Create Hardware objects and start virtual instances
    preconditions:
      - echo $TINKERBELL_IP | fgrep .
      - echo $DNS_IP | fgrep .
      - echo $BMAAS_NAMESPACE | grep -qe "[a-z]"
    cmds:
      - for: {var: hardwares}
        cmd: incus init {{.ITEM.hostname}} --empty --vm --no-profiles -c limits.cpu=2 -c limits.memory=4GiB -d root,size=15GiB
      - for: {var: hardwares}
        cmd: incus config set {{.ITEM.hostname}} security.secureboot=false
      - for: {var: hardwares}
        cmd: incus config device add {{.ITEM.hostname}} eth0 nic network=services0 hwaddr="{{.ITEM.mac}}"
      - for: {var: hardwares}
        cmd: incus start {{.ITEM.hostname}}
      - mkdir -p dist
      - jinja2 --strict -D dns_ipaddr=$DNS_IP -D namespace=$BMAAS_NAMESPACE hardwares.yaml.j2 -o dist/hardwares.yaml
      - kubectl apply -f dist/hardwares.yaml
  #############################################################################
  # Create tinkerbell and cluster manifests
  create-capi-vm:
    desc: Create tinkerbell template and workflow
    preconditions:
      - echo $BMAAS_NAMESPACE | grep -qe "[a-z]"
      - echo $TINKERBELL_IP| grep -qe "[a-z0-9]"
      - test -f ../../../ring0/dist/talosconfig
      - test -f ../../../ring0/dist/bundle.crt
    vars:
      announcement_interface:
        sh: talosctl --talosconfig ../../../ring0/dist/talosconfig -n management -e management get addresses | grep $INSTANCE_MANAGEMENT_SERVICES_IPADDR_CIDR | awk '{print $4}' | tail -n1 | awk -F/ '{print $1}'
      jinja_opts: --strict
      butane_system_base64:
        sh: base64 -i system.yaml
      butane_kubeadm_base64:
        sh: base64 -i kubeadm.yaml
      butane_merge_base64:
        sh: base64 -i merge.yaml
      bundle_crt_base64:
        sh: base64 -i ../../../ring0/dist/bundle.crt
      jinja_variables: -D namespace=$BMAAS_NAMESPACE -D announcement_interface={{.announcement_interface}} -D cp_host={{.cp_host}} -D ts_suffix={{.ts_suffix}} -D butane_system_base64={{.butane_system_base64}} -D butane_kubeadm_base64={{.butane_kubeadm_base64}} -D butane_merge_base64={{.butane_merge_base64}} -D bundle_crt_base64={{.bundle_crt_base64}}
    cmds:
      - mkdir -p dist
      - jinja2 {{.jinja_opts}} {{.jinja_variables}} -o dist/capi-vm.yaml capi-vm.yaml.j2
      - kubectl apply -n $BMAAS_NAMESPACE --wait -f dist/capi-vm.yaml
      - kubectl wait --for=create secret/capi-vm-kubeconfig -n $BMAAS_NAMESPACE --timeout=300s
      - kubectl get secret -n $BMAAS_NAMESPACE capi-vm-kubeconfig -o yaml  | yq '.data.value' | base64 -d | sed 's/{{.cp_host}}/capi-vm/' > dist/kubeconfig
      - while ! kubectl get workflow -n $BMAAS_NAMESPACE | grep capi-vm-worker ; do sleep 10 ; done
    generates:
      - dist/capi-vm.yaml
      - dist/kubeconfig
    sources:
      - capi-vm.yaml.j2
  deploy-cilium:
    desc: Deploy cilium
    preconditions:
      - test -f dist/kubeconfig
    vars:
      jinja_opts: --strict
      jinja_variables: -D cp_host={{.cp_host}}
      workflow_name:
        sh: kubectl get workflow -n $BMAAS_NAMESPACE | awk '/capi/{print $1}'
    cmds:
      - kubectl wait --for=jsonpath='{.status.state}=SUCCESS' workflow/{{.workflow_name}} -n $BMAAS_NAMESPACE --timeout=15m
      - jinja2 {{.jinja_opts}} {{.jinja_variables}} -o dist/cilium.yaml cilium.yaml.j2
      - cilium install --kubeconfig dist/kubeconfig --values dist/cilium.yaml
      - cilium status --wait --kubeconfig dist/kubeconfig
